{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOY PROBLEM\n",
    "\n",
    "The purpose of this notebook is to illustrate the impact that a classifier can have on the world. \n",
    "\n",
    "The toy example is as follows:\n",
    "\n",
    "In a magical land, there's 100 blue haired people and 100 green haired people. Every day, they can eat normal food, or they can steal a cookie from a sacred cookie jar in their house. The initial probabilities of stealing a cookie are $\\mu_{blue}=0.6$ for the blues and $\\mu_{green}=0.4$ for the greens, as a population. There is also a central fucked up dystopian government, which sends police to the houses of people that it thinks are likely to have stolen a cookie. If the police catches someone stealing a cookie, that person's food is confiscated for the day, and they go hungry (which means that they're likelier to want a cookie the next day, because cookies are more filling than normal food). If not, they progressively lose interest in stealing the cookies, and their probabilities of stealing a cookie diminishes. \n",
    "\n",
    "## More formally\n",
    "\n",
    "Each individual is associated with a feature vector $X$, which is made up of different distributions with mean $\\mu$.\n",
    "At each time step, the means mu are used to generate actual stealing data, i.e. to determine if an individual stole a cookie or not, represented by a vector $y$ full of zeros and ones.\n",
    "This data is fed into a logistic regression classifier.\n",
    "Each time step, and for each individual, the classifier predicts whether or not someone will steal a cookie, and depending on that prediction, will decide to send or not send a policeman to their house. If the police is sent to someone's house, and that person gets caught stealing a cookie, that person's $\\mu$ increases by $\\alpha$. Otherwise, it decreases by $\\beta$.\n",
    "\n",
    "Then I plot each person's $\\mu$ over time to see how it evolves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import things\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "#set up hyperparameters\n",
    "#initial probability that blue and green steal\n",
    "mu_blue = 0.65\n",
    "mu_green = 0.35\n",
    "#number of people in each population\n",
    "N = 100\n",
    "#probability increase/decrease if caught/not caught\n",
    "alpha = 0.003\n",
    "beta = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate random uniforms between 0 and 1\n",
    "y_blue = np.random.uniform(0,1, (N,1))\n",
    "y_green = np.random.uniform(0,1, (N,1))\n",
    "\n",
    "#replace each value with 0 or 1\n",
    "y_blue[y_blue > mu_blue] = 1\n",
    "y_blue[y_blue <= mu_blue] = 0\n",
    "y_green[y_green > mu_green] = 1\n",
    "y_green[y_green <= mu_green] = 0\n",
    "\n",
    "y_green = np.abs(y_green - 1)\n",
    "y_blue = np.abs(y_blue - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the goal is to make feature vectors for blue and green. This is gonna be simpler than last time: there'll only be a single feature, which is a noisy estimate of the true probability. \n",
    "We do that, and make a historical X and y, to make a preliminary model, and then also make a real X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create identities for each being:\n",
    "    #give them a number\n",
    "identities = np.arange(2*N)\n",
    "identities = np.reshape(identities,(200,1))\n",
    "    #give them a base rate of stealing the cookies\n",
    "base_rates_blue = np.ones((N, 1))*mu_blue\n",
    "base_rates_green = np.ones((N, 1))*mu_green\n",
    "base_rates = np.concatenate((base_rates_blue, base_rates_green), axis=0)\n",
    "\n",
    "#create X_blue\n",
    "X_blue= np.random.normal(mu_blue, 0.001, (N,1))\n",
    "\n",
    "#create X_green\n",
    "X_green= np.random.normal(mu_green, 0.001, (N,1))\n",
    "\n",
    "#append identities, base rates, and mix everything together\n",
    "big_X = np.concatenate((X_blue, X_green), axis=0)\n",
    "big_X = np.concatenate((big_X, identities, base_rates), axis=1)\n",
    "np.random.shuffle(big_X)\n",
    "\n",
    "\n",
    "X = np.copy(big_X[:,0])\n",
    "identities = big_X[:,1]\n",
    "base_rates = big_X[:,2]\n",
    "\n",
    "historical_X_blue = np.concatenate((X_blue, y_blue), axis = 1)\n",
    "historical_X_green = np.concatenate((X_green, y_green), axis = 1)\n",
    "historical_X = np.concatenate((historical_X_blue, historical_X_green), axis=0)\n",
    "np.random.shuffle(historical_X)\n",
    "\n",
    "historical_y = historical_X[:,1]\n",
    "historical_X = historical_X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly train model by making up a y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "model = LogisticRegression()\n",
    "model = model.fit(historical_X.reshape(-1,1), historical_y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "model.score(historical_X.reshape(-1, 1), historical_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hella functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to generate actual stealing or not stealing events\n",
    "def did_they_steal(base_rates):\n",
    "    \n",
    "    y = np.zeros((len(base_rates),1))\n",
    "    \n",
    "    for i in range(len(base_rates)):\n",
    "        if base_rates[i] > np.random.uniform(0,1):\n",
    "            y[i] = 1\n",
    "    \n",
    "    return y\n",
    "\n",
    "#function to update base rates\n",
    "def update_base_rates(base_rates, y, predictions, alpha, beta):\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == predictions[i] and y[i] == 1 and (base_rates[i] + beta)  < 1:\n",
    "            base_rates[i] = base_rates[i] + beta\n",
    "        elif base_rates[i] > alpha:\n",
    "            base_rates[i] = base_rates[i] - alpha\n",
    "            \n",
    "    return base_rates\n",
    "\n",
    "#function that uses new base rates to create new feature vector\n",
    "def update_X(base_rates):\n",
    "    for i in range(len(base_rates)):\n",
    "        new_vec1 = np.random.normal(base_rates[i]*3, 1, (1, 3))\n",
    "        new_vec2 = np.random.exponential(base_rates[i]+1, (1, 3))\n",
    "        new_vec3 = np.random.binomial(100, base_rates[i]**2, (1, 3))\n",
    "        new_vec4 = np.random.standard_normal((1, 1))\n",
    "        new_features = (new_vec1, new_vec2, new_vec3, new_vec4)\n",
    "\n",
    "        X[i] = np.concatenate(new_features, axis=1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "#predicts probability that someone stole\n",
    "def predict_probs_steal(X, modelcoef, modelintercept):\n",
    "    predictions = 1 / (1 + np.exp(-(X @ np.transpose(modelcoef) + modelintercept)))\n",
    "    predictions[predictions > 0.5] = 1\n",
    "    predictions[predictions <= 0.5] = 0\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
